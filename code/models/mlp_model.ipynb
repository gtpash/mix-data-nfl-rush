{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "from numpy.matlib import repmat\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "pd.options.display.max_columns = 100\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "from fuzzywuzzy import fuzz\n",
    "import datetime\n",
    "import sklearn\n",
    "\n",
    "#for image generation\n",
    "from scipy import stats\n",
    "from scipy.special import expit\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Training data is in the competition dataset\n",
    "train_df = pd.read_csv('data/train.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# who needs tidyverse? it's all just SQL in the end\n",
    "\n",
    "## TODO: fix player direction mapping\n",
    "\n",
    "# standardize co-ordinates, courtesy of Michael Lopez's R implementation\n",
    "# https://www.kaggle.com/statsbymichaellopez/nfl-tracking-wrangling-voronoi-and-sonars\n",
    "\n",
    "def clean_df(df):\n",
    "    # first, re-map a few team names\n",
    "    di = {\"ARZ\":\"ARI\", \"BLT\":\"BAL\", \"CLV\":\"CLE\", \"HST\":\"HOU\"}\n",
    "    df = df.replace({'PossessionTeam':di, 'FieldPosition':di})\n",
    "    di = {\"ACE\":\"SINGLEBACK\", np.nan:\"NONE\"}\n",
    "    df = df.replace({'OffenseFormation':di})\n",
    "\n",
    "    df = (df \n",
    "            .assign(ToLeft=df['PlayDirection']=='left')\n",
    "            .assign(BallCarrier=df['NflId']==train_df['NflIdRusher'])\n",
    "           )\n",
    "\n",
    "    df = df.assign(TeamOnOffense=np.where(df['PossessionTeam']==df['HomeTeamAbbr'],'home','away'))\n",
    "\n",
    "    df = (df\n",
    "            .assign(IsOnOffense=df['Team']==df['TeamOnOffense'])\n",
    "            .assign(YardsFromOwnGoal=np.where(df['FieldPosition']==df['PossessionTeam'], df['YardLine'], 50 + (50-df['YardLine'])))\n",
    "           )\n",
    "\n",
    "    # standardize field positions\n",
    "    df = (df\n",
    "            .assign(YardsFromOwnGoal=np.where(df['YardLine']==50, 50, df['YardsFromOwnGoal']))\n",
    "            .assign(X=np.where(df['ToLeft'], 120-df['X'], df['X'])-10)\n",
    "            .assign(Y=np.where(df['ToLeft'], 160/3-df['Y'], df['Y']))\n",
    "           )\n",
    "\n",
    "    # standardize player directions (- to swtich from cw to ccw, + 90 to rotate so 0 = x-axis, -180 if going left to flip field)\n",
    "    df = (df\n",
    "            .assign(Dir=np.radians(np.where(~df['ToLeft'], -df['Dir'], -df['Dir']-180)+90))\n",
    "           )\n",
    "    \n",
    "    # play duration so far\n",
    "    df = (df\n",
    "             .assign(Duration=(pd.to_datetime(df['TimeHandoff']) - pd.to_datetime(df['TimeSnap']))/np.timedelta64(1,'s'))\n",
    "         )\n",
    "    \n",
    "    # drop columns that we will not use\n",
    "    df = (df\n",
    "             .drop(columns=['Temperature', 'WindSpeed', 'WindDirection', 'Stadium', 'DisplayName', 'JerseyNumber',\n",
    "                           'Season', 'Orientation', 'Humidity', 'Week', 'PlayerCollegeName', 'TimeSnap', 'TimeHandoff',\n",
    "                           'Location', 'PlayerBirthDate', 'PlayerHeight', 'Position', 'GameWeather']))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleandf = clean_df(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## helper codes to retrieve game state information\n",
    "\n",
    "def split_personnel(s):\n",
    "    splits = s.split(',')\n",
    "    for i in range(len(splits)):\n",
    "        splits[i] = splits[i].strip()\n",
    "\n",
    "    return splits\n",
    "\n",
    "def defense_formation(l):\n",
    "    dl = 0\n",
    "    lb = 0\n",
    "    db = 0\n",
    "    other = 0\n",
    "\n",
    "    for position in l:\n",
    "        sub_string = position.split(' ')\n",
    "        if sub_string[1] == 'DL':\n",
    "            dl += int(sub_string[0])\n",
    "        elif sub_string[1] in ['LB','OL']:\n",
    "            lb += int(sub_string[0])\n",
    "        else:\n",
    "            db += int(sub_string[0])\n",
    "\n",
    "    counts = (dl,lb,db,other)\n",
    "\n",
    "    return counts\n",
    "\n",
    "def offense_formation(l):\n",
    "    qb = 0\n",
    "    rb = 0\n",
    "    wr = 0\n",
    "    te = 0\n",
    "    ol = 0\n",
    "\n",
    "    sub_total = 0\n",
    "    qb_listed = False\n",
    "    for position in l:\n",
    "        sub_string = position.split(' ')\n",
    "        pos = sub_string[1]\n",
    "        cnt = int(sub_string[0])\n",
    "\n",
    "        if pos == 'QB':\n",
    "            qb += cnt\n",
    "            sub_total += cnt\n",
    "            qb_listed = True\n",
    "        # Assuming LB is a line backer lined up as full back\n",
    "        elif pos in ['RB','LB']:\n",
    "            rb += cnt\n",
    "            sub_total += cnt\n",
    "        # Assuming DB is a defensive back and lined up as WR\n",
    "        elif pos in ['WR','DB']:\n",
    "            wr += cnt\n",
    "            sub_total += cnt\n",
    "        elif pos == 'TE':\n",
    "            te += cnt\n",
    "            sub_total += cnt\n",
    "        # Assuming DL is a defensive lineman lined up as an additional line man\n",
    "        else:\n",
    "            ol += cnt\n",
    "            sub_total += cnt\n",
    "\n",
    "    # If not all 11 players were noted at given positions we need to make some assumptions\n",
    "    # I will assume if a QB is not listed then there was 1 QB on the play\n",
    "    # If a QB is listed then I'm going to assume the rest of the positions are at OL\n",
    "    # This might be flawed but it looks like RB, TE and WR are always listed in the personnel\n",
    "    if sub_total < 11:\n",
    "        diff = 11 - sub_total\n",
    "        if not qb_listed:\n",
    "            qb += 1\n",
    "            diff -= 1\n",
    "        ol += diff\n",
    "\n",
    "    counts = (qb,rb,wr,te,ol)\n",
    "\n",
    "    return counts\n",
    "\n",
    "def personnel_features(df):\n",
    "    personnel = df[['GameId','PlayId','OffensePersonnel','DefensePersonnel']].drop_duplicates()\n",
    "    personnel['DefensePersonnel'] = personnel['DefensePersonnel'].apply(lambda x: split_personnel(x))\n",
    "    personnel['DefensePersonnel'] = personnel['DefensePersonnel'].apply(lambda x: defense_formation(x))\n",
    "    personnel['DL'] = personnel['DefensePersonnel'].apply(lambda x: x[0])\n",
    "    personnel['LB'] = personnel['DefensePersonnel'].apply(lambda x: x[1])\n",
    "    personnel['DB'] = personnel['DefensePersonnel'].apply(lambda x: x[2])\n",
    "\n",
    "    personnel['OffensePersonnel'] = personnel['OffensePersonnel'].apply(lambda x: split_personnel(x))\n",
    "    personnel['OffensePersonnel'] = personnel['OffensePersonnel'].apply(lambda x: offense_formation(x))\n",
    "    personnel['QB'] = personnel['OffensePersonnel'].apply(lambda x: x[0])\n",
    "    personnel['RB'] = personnel['OffensePersonnel'].apply(lambda x: x[1])\n",
    "    personnel['WR'] = personnel['OffensePersonnel'].apply(lambda x: x[2])\n",
    "    personnel['TE'] = personnel['OffensePersonnel'].apply(lambda x: x[3])\n",
    "    personnel['OL'] = personnel['OffensePersonnel'].apply(lambda x: x[4])\n",
    "\n",
    "    # Let's create some features to specify if the OL is covered\n",
    "    personnel['OL_diff'] = personnel['OL'] - personnel['DL']\n",
    "    personnel['OL_TE_diff'] = (personnel['OL'] + personnel['TE']) - personnel['DL']\n",
    "    # Let's create a feature to specify if the defense is preventing the run\n",
    "    # Let's just assume 7 or more DL and LB is run prevention\n",
    "    personnel['run_def'] = (personnel['DL'] + personnel['LB'] > 6).astype(int)\n",
    "\n",
    "    personnel.drop(['OffensePersonnel','DefensePersonnel'], axis=1, inplace=True)\n",
    "\n",
    "    return personnel\n",
    "\n",
    "def clean_stadium_type(row):\n",
    "    if not pd.isnull(row['StadiumType']):\n",
    "        if fuzz.partial_ratio(row['StadiumType'],'outdoor') > 75:\n",
    "            st = 'outdoor'\n",
    "        else:\n",
    "            st = 'indoor'\n",
    "    else:\n",
    "        st = 'indoor'\n",
    "    return st\n",
    "\n",
    "def clean_field_type(row):\n",
    "    if not pd.isnull(row['Turf']):\n",
    "        if fuzz.partial_ratio(row['Turf'],'natural grass') > 75:\n",
    "            ft = 'natural'\n",
    "        else:\n",
    "            ft = 'artificial'\n",
    "    else:\n",
    "        ft = 'artificial'\n",
    "    return ft\n",
    "\n",
    "def time_remaining(row):\n",
    "    gc = row['GameClock']\n",
    "    tmp = gc.split(':')[:-1]\n",
    "    tr = (int(tmp[0])*3600) + (int(tmp[1]))\n",
    "    tr = tr/3600/15\n",
    "    return tr\n",
    "\n",
    "def get_score_diff(row):\n",
    "    if row['TeamOnOffense'] == 'home':\n",
    "        scoreDiff = row['HomeScoreBeforePlay'] - row['VisitorScoreBeforePlay']\n",
    "    else: \n",
    "        scoreDiff = row['VisitorScoreBeforePlay'] - row['HomeScoreBeforePlay']\n",
    "    return scoreDiff\n",
    "\n",
    "def distance_remaining(row):\n",
    "    dist_rem = (100 - row['YardsFromOwnGoal'])/100\n",
    "    return dist_rem\n",
    "\n",
    "def one_hot_enc(df, var):\n",
    "    one_hot = pd.get_dummies(df[var])\n",
    "    df = (df\n",
    "              .drop(var, axis=1)\n",
    "              .join(one_hot)\n",
    "         )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional cleaning steps\n",
    "cleandf['Turf'] = cleandf.apply(clean_field_type, axis=1)\n",
    "cleandf['StadiumType'] = cleandf.apply(clean_stadium_type, axis=1)\n",
    "cleandf['DistanceRemaining'] = cleandf.apply(distance_remaining, axis=1)\n",
    "\n",
    "cleandf = pd.merge(cleandf,personnel_features(cleandf),on=['GameId','PlayId'],how='inner')\n",
    "\n",
    "cleandf = cleandf.drop(columns=['OffensePersonnel','DefensePersonnel'])\n",
    "\n",
    "cleandf['ScoreDiff'] = cleandf.apply(get_score_diff, axis=1)\n",
    "\n",
    "cleandf['GameClock'] = cleandf.apply(time_remaining, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# game state information for each row\n",
    "\n",
    "plays = cleandf.groupby('PlayId').first().drop(columns=['Team', 'X', 'Y', 'Dir', 'NflId', 'PossessionTeam',\n",
    "                                                        'ToLeft', 'IsOnOffense', 'BallCarrier', 'HomeTeamAbbr',\n",
    "                                                       'VisitorTeamAbbr', 'PlayDirection', 'YardLine', \n",
    "                                                       'A', 'S', 'NflIdRusher', 'PlayerWeight', 'FieldPosition',\n",
    "                                                       'Dis', 'GameId', 'HomeScoreBeforePlay', \n",
    "                                                        'VisitorScoreBeforePlay', 'YardsFromOwnGoal'])\n",
    "# one-hot categoricals\n",
    "plays = one_hot_enc(plays, 'OffenseFormation')\n",
    "di = {\"outdoor\":1, \"indoor\":0, \"artificial\":1, \"natural\":0, \"home\":1, \"away\":0}\n",
    "plays = plays.replace({'StadiumType':di, 'Turf':di, 'TeamOnOffense':di})\n",
    "di = {1:\"D1\", 2:\"D2\", 3:\"D3\", 4:\"D4\"}\n",
    "plays = plays.replace({'Down':di})\n",
    "plays = one_hot_enc(plays, 'Down')\n",
    "di = {1:\"Q1\", 2:\"Q2\", 3:\"Q3\", 4:\"Q4\", 5:\"OT\"}\n",
    "plays = plays.replace({'Quarter':di})\n",
    "plays = one_hot_enc(plays, 'Quarter')\n",
    "\n",
    "# add play id back to groupby dataframe\n",
    "pids = plays.index.tolist()\n",
    "plays['PlayId'] = pids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outcomes = pd.DataFrame.to_numpy(plays['Yards'])\n",
    "plays = plays.drop(columns=['Yards', 'PlayId'])\n",
    "plays = pd.DataFrame.to_numpy(plays)\n",
    "# concat x,y-data values for all players\n",
    "positions = train_df[['X','Y']]\n",
    "positions = np.array(positions).reshape(-1, len(positions.columns)*22)\n",
    "data = np.concatenate((plays, positions), axis=1)\n",
    "data = data.astype('float')\n",
    "\n",
    "# handle remaining nans\n",
    "nanInd = np.argwhere(np.isnan(data))\n",
    "data[nanInd[:,0],nanInd[:,1]] = np.zeros((1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map true outcomes to correct representation\n",
    "n = len(outcomes)\n",
    "ystar = np.zeros((n,199))\n",
    "for ii in range(n):\n",
    "    y = int(outcomes[ii]) \n",
    "    yvec = np.concatenate((np.zeros((1,y+99)),np.ones((1,100-y))), axis = 1)\n",
    "    ystar[ii,:] = yvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# required packages for MLP model\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential, Model, model_from_json\n",
    "from keras.layers import Dense, BatchNormalization, Dropout\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "from keras.optimizers import TFOptimizer, Adam\n",
    "\n",
    "import keras.backend as kb\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CRPS(yTrue, yPred):\n",
    "    yPred = kb.cumsum(yPred, axis=1)\n",
    "    return kb.mean(kb.sum(kb.square(yPred - yTrue), axis=1)) / 199"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get test/val/train splits\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, ystar, test_size=0.3)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3)\n",
    "\n",
    "# model definition\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=data.shape[1], activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(256, input_dim=data.shape[1], activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(199, input_dim=data.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss=CRPS,\n",
    "              metrics = [CRPS],\n",
    "              optimizer=Adam())\n",
    "\n",
    "mlp_json = model.to_json()\n",
    "with open(\"./mlp/mlp.json\", \"w\") as json_file:\n",
    "    json_file.write(mlp_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11353 samples, validate on 4866 samples\n",
      "Epoch 1/100\n",
      "11353/11353 [==============================] - 1s 81us/step - loss: 0.0141 - CRPS: 0.0141 - val_loss: 0.0139 - val_CRPS: 0.0139\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.01391, saving model to ./mlp/weights/mlpBestWeights.h5\n",
      "Epoch 2/100\n",
      "11353/11353 [==============================] - 1s 80us/step - loss: 0.0141 - CRPS: 0.0141 - val_loss: 0.0139 - val_CRPS: 0.0139\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.01391 to 0.01390, saving model to ./mlp/weights/mlpBestWeights.h5\n",
      "Epoch 3/100\n",
      "11353/11353 [==============================] - 1s 84us/step - loss: 0.0141 - CRPS: 0.0141 - val_loss: 0.0139 - val_CRPS: 0.0139\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.01390\n",
      "Epoch 4/100\n",
      "11353/11353 [==============================] - 1s 94us/step - loss: 0.0141 - CRPS: 0.0141 - val_loss: 0.0139 - val_CRPS: 0.0139\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.01390 to 0.01390, saving model to ./mlp/weights/mlpBestWeights.h5\n",
      "Epoch 5/100\n",
      "11353/11353 [==============================] - 1s 82us/step - loss: 0.0141 - CRPS: 0.0140 - val_loss: 0.0139 - val_CRPS: 0.0139\n",
      "\n",
      "Epoch 00005: saving model to ./mlp/weights/mlpWeights05.h5\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.01390\n",
      "Epoch 6/100\n",
      "11353/11353 [==============================] - 1s 72us/step - loss: 0.0141 - CRPS: 0.0141 - val_loss: 0.0139 - val_CRPS: 0.0139\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.01390\n",
      "Epoch 7/100\n",
      "11353/11353 [==============================] - 1s 90us/step - loss: 0.0141 - CRPS: 0.0141 - val_loss: 0.0139 - val_CRPS: 0.0139\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.01390\n",
      "Epoch 8/100\n",
      "11353/11353 [==============================] - 1s 85us/step - loss: 0.0141 - CRPS: 0.0141 - val_loss: 0.0139 - val_CRPS: 0.0139\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.01390\n",
      "Epoch 9/100\n",
      "11353/11353 [==============================] - 1s 83us/step - loss: 0.0141 - CRPS: 0.0141 - val_loss: 0.0139 - val_CRPS: 0.0139\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.01390\n",
      "Epoch 10/100\n",
      "11353/11353 [==============================] - 1s 79us/step - loss: 0.0140 - CRPS: 0.0141 - val_loss: 0.0139 - val_CRPS: 0.0139\n",
      "\n",
      "Epoch 00010: saving model to ./mlp/weights/mlpWeights10.h5\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.01390 to 0.01390, saving model to ./mlp/weights/mlpBestWeights.h5\n",
      "Epoch 11/100\n",
      "11353/11353 [==============================] - 1s 79us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0139 - val_CRPS: 0.0139\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.01390\n",
      "Epoch 12/100\n",
      "11353/11353 [==============================] - 1s 80us/step - loss: 0.0141 - CRPS: 0.0140 - val_loss: 0.0139 - val_CRPS: 0.0139\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.01390\n",
      "Epoch 13/100\n",
      "11353/11353 [==============================] - 1s 85us/step - loss: 0.0141 - CRPS: 0.0141 - val_loss: 0.0139 - val_CRPS: 0.0139\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.01390\n",
      "Epoch 14/100\n",
      "11353/11353 [==============================] - 1s 80us/step - loss: 0.0141 - CRPS: 0.0141 - val_loss: 0.0139 - val_CRPS: 0.0139\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.01390\n",
      "Epoch 15/100\n",
      "11353/11353 [==============================] - 1s 80us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0139 - val_CRPS: 0.0139\n",
      "\n",
      "Epoch 00015: saving model to ./mlp/weights/mlpWeights15.h5\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01390\n",
      "Epoch 16/100\n",
      "11353/11353 [==============================] - 1s 80us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0139 - val_CRPS: 0.0139\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.01390\n",
      "Epoch 17/100\n",
      "11353/11353 [==============================] - 1s 81us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0139 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.01390\n",
      "Epoch 18/100\n",
      "11353/11353 [==============================] - 1s 81us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0139 - val_CRPS: 0.0139\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.01390\n",
      "Epoch 19/100\n",
      "11353/11353 [==============================] - 1s 82us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0139 - val_CRPS: 0.0139\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.01390\n",
      "Epoch 20/100\n",
      "11353/11353 [==============================] - 1s 81us/step - loss: 0.0141 - CRPS: 0.0141 - val_loss: 0.0139 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00020: saving model to ./mlp/weights/mlpWeights20.h5\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01390\n",
      "Epoch 21/100\n",
      "11353/11353 [==============================] - 1s 80us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0139 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.01390\n",
      "Epoch 22/100\n",
      "11353/11353 [==============================] - 1s 80us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0139 - val_CRPS: 0.0139\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.01390\n",
      "Epoch 23/100\n",
      "11353/11353 [==============================] - 1s 81us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0140 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.01390\n",
      "Epoch 24/100\n",
      "11353/11353 [==============================] - 1s 81us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0140 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.01390\n",
      "Epoch 25/100\n",
      "11353/11353 [==============================] - 1s 85us/step - loss: 0.0141 - CRPS: 0.0140 - val_loss: 0.0140 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00025: saving model to ./mlp/weights/mlpWeights25.h5\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.01390\n",
      "Epoch 26/100\n",
      "11353/11353 [==============================] - 1s 84us/step - loss: 0.0140 - CRPS: 0.0141 - val_loss: 0.0140 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.01390\n",
      "Epoch 27/100\n",
      "11353/11353 [==============================] - 1s 104us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0140 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.01390\n",
      "Epoch 28/100\n",
      "11353/11353 [==============================] - 1s 80us/step - loss: 0.0140 - CRPS: 0.0141 - val_loss: 0.0139 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.01390\n",
      "Epoch 29/100\n",
      "11353/11353 [==============================] - 1s 82us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0139 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.01390\n",
      "Epoch 30/100\n",
      "11353/11353 [==============================] - 1s 84us/step - loss: 0.0140 - CRPS: 0.0141 - val_loss: 0.0139 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00030: saving model to ./mlp/weights/mlpWeights30.h5\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.01390\n",
      "Epoch 31/100\n",
      "11353/11353 [==============================] - 1s 129us/step - loss: 0.0141 - CRPS: 0.0140 - val_loss: 0.0140 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.01390\n",
      "Epoch 32/100\n",
      "11353/11353 [==============================] - 1s 89us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0140 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.01390\n",
      "Epoch 33/100\n",
      "11353/11353 [==============================] - 1s 77us/step - loss: 0.0141 - CRPS: 0.0140 - val_loss: 0.0139 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.01390\n",
      "Epoch 34/100\n",
      "11353/11353 [==============================] - 1s 81us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0140 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.01390\n",
      "Epoch 35/100\n",
      "11353/11353 [==============================] - 1s 111us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0140 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00035: saving model to ./mlp/weights/mlpWeights35.h5\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.01390\n",
      "Epoch 36/100\n",
      "11353/11353 [==============================] - 1s 87us/step - loss: 0.0140 - CRPS: 0.0145 - val_loss: 0.0140 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.01390\n",
      "Epoch 37/100\n",
      "11353/11353 [==============================] - 1s 84us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0140 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.01390\n",
      "Epoch 38/100\n",
      "11353/11353 [==============================] - 1s 85us/step - loss: 0.0141 - CRPS: 0.0140 - val_loss: 0.0140 - val_CRPS: 0.0140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00038: val_loss did not improve from 0.01390\n",
      "Epoch 39/100\n",
      "11353/11353 [==============================] - 1s 78us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0139 - val_CRPS: 0.0139\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.01390\n",
      "Epoch 40/100\n",
      "11353/11353 [==============================] - 1s 76us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0140 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00040: saving model to ./mlp/weights/mlpWeights40.h5\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.01390\n",
      "Epoch 41/100\n",
      "11353/11353 [==============================] - 1s 76us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0139 - val_CRPS: 0.0139\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.01390\n",
      "Epoch 42/100\n",
      "11353/11353 [==============================] - 1s 82us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0139 - val_CRPS: 0.0139\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.01390\n",
      "Epoch 43/100\n",
      "11353/11353 [==============================] - 1s 76us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0139 - val_CRPS: 0.0139\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.01390\n",
      "Epoch 44/100\n",
      "11353/11353 [==============================] - 1s 88us/step - loss: 0.0140 - CRPS: 0.0141 - val_loss: 0.0140 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.01390\n",
      "Epoch 45/100\n",
      "11353/11353 [==============================] - 1s 80us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0140 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00045: saving model to ./mlp/weights/mlpWeights45.h5\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.01390\n",
      "Epoch 46/100\n",
      "11353/11353 [==============================] - 1s 87us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0140 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.01390\n",
      "Epoch 47/100\n",
      "11353/11353 [==============================] - 1s 88us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0139 - val_CRPS: 0.0139\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.01390\n",
      "Epoch 48/100\n",
      "11353/11353 [==============================] - 1s 82us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0140 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.01390\n",
      "Epoch 49/100\n",
      "11353/11353 [==============================] - 1s 80us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0140 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.01390\n",
      "Epoch 50/100\n",
      "11353/11353 [==============================] - 1s 80us/step - loss: 0.0140 - CRPS: 0.0141 - val_loss: 0.0139 - val_CRPS: 0.0139\n",
      "\n",
      "Epoch 00050: saving model to ./mlp/weights/mlpWeights50.h5\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.01390\n",
      "Epoch 51/100\n",
      "11353/11353 [==============================] - 1s 80us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0139 - val_CRPS: 0.0139\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.01390\n",
      "Epoch 52/100\n",
      "11353/11353 [==============================] - 1s 81us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0140 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.01390\n",
      "Epoch 53/100\n",
      "11353/11353 [==============================] - 1s 80us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0140 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.01390\n",
      "Epoch 54/100\n",
      "11353/11353 [==============================] - 1s 82us/step - loss: 0.0141 - CRPS: 0.0140 - val_loss: 0.0140 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.01390\n",
      "Epoch 55/100\n",
      "11353/11353 [==============================] - 1s 100us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0139 - val_CRPS: 0.0139\n",
      "\n",
      "Epoch 00055: saving model to ./mlp/weights/mlpWeights55.h5\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.01390\n",
      "Epoch 56/100\n",
      "11353/11353 [==============================] - 1s 79us/step - loss: 0.0140 - CRPS: 0.0141 - val_loss: 0.0139 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.01390\n",
      "Epoch 57/100\n",
      "11353/11353 [==============================] - 1s 78us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0140 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.01390\n",
      "Epoch 58/100\n",
      "11353/11353 [==============================] - 1s 78us/step - loss: 0.0140 - CRPS: 0.0141 - val_loss: 0.0140 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.01390\n",
      "Epoch 59/100\n",
      "11353/11353 [==============================] - 1s 80us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0140 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.01390\n",
      "Epoch 60/100\n",
      "11353/11353 [==============================] - 1s 77us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0139 - val_CRPS: 0.0139\n",
      "\n",
      "Epoch 00060: saving model to ./mlp/weights/mlpWeights60.h5\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.01390\n",
      "Epoch 61/100\n",
      "11353/11353 [==============================] - 1s 77us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0139 - val_CRPS: 0.0139\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.01390\n",
      "Epoch 62/100\n",
      "11353/11353 [==============================] - 1s 82us/step - loss: 0.0140 - CRPS: 0.0141 - val_loss: 0.0140 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.01390\n",
      "Epoch 63/100\n",
      "11353/11353 [==============================] - 1s 80us/step - loss: 0.0140 - CRPS: 0.0141 - val_loss: 0.0139 - val_CRPS: 0.0139\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.01390\n",
      "Epoch 64/100\n",
      "11353/11353 [==============================] - 1s 84us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0139 - val_CRPS: 0.0139\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.01390\n",
      "Epoch 65/100\n",
      "11353/11353 [==============================] - 1s 84us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0140 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00065: saving model to ./mlp/weights/mlpWeights65.h5\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.01390\n",
      "Epoch 66/100\n",
      "11353/11353 [==============================] - 1s 79us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0140 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.01390\n",
      "Epoch 67/100\n",
      "11353/11353 [==============================] - 1s 81us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0139 - val_CRPS: 0.0139\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.01390\n",
      "Epoch 68/100\n",
      "11353/11353 [==============================] - 1s 79us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0139 - val_CRPS: 0.0139\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.01390\n",
      "Epoch 69/100\n",
      "11353/11353 [==============================] - 1s 80us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0139 - val_CRPS: 0.0139\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.01390\n",
      "Epoch 70/100\n",
      "11353/11353 [==============================] - 1s 81us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0139 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00070: saving model to ./mlp/weights/mlpWeights70.h5\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.01390\n",
      "Epoch 71/100\n",
      "11353/11353 [==============================] - 1s 89us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0139 - val_CRPS: 0.0139\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.01390\n",
      "Epoch 72/100\n",
      "11353/11353 [==============================] - 1s 81us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0139 - val_CRPS: 0.0139\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.01390\n",
      "Epoch 73/100\n",
      "11353/11353 [==============================] - 1s 79us/step - loss: 0.0140 - CRPS: 0.0141 - val_loss: 0.0140 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.01390\n",
      "Epoch 74/100\n",
      "11353/11353 [==============================] - 1s 78us/step - loss: 0.0140 - CRPS: 0.0142 - val_loss: 0.0140 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.01390\n",
      "Epoch 75/100\n",
      "11353/11353 [==============================] - 1s 78us/step - loss: 0.0140 - CRPS: 0.0141 - val_loss: 0.0140 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00075: saving model to ./mlp/weights/mlpWeights75.h5\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.01390\n",
      "Epoch 76/100\n",
      "11353/11353 [==============================] - 1s 83us/step - loss: 0.0141 - CRPS: 0.0141 - val_loss: 0.0139 - val_CRPS: 0.0139\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.01390\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11353/11353 [==============================] - 1s 82us/step - loss: 0.0140 - CRPS: 0.0141 - val_loss: 0.0139 - val_CRPS: 0.0139\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.01390\n",
      "Epoch 78/100\n",
      "11353/11353 [==============================] - 1s 79us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0139 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.01390\n",
      "Epoch 79/100\n",
      "11353/11353 [==============================] - 1s 79us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0139 - val_CRPS: 0.0139\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.01390\n",
      "Epoch 80/100\n",
      "11353/11353 [==============================] - 1s 82us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0139 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00080: saving model to ./mlp/weights/mlpWeights80.h5\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.01390\n",
      "Epoch 81/100\n",
      "11353/11353 [==============================] - 1s 79us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0139 - val_CRPS: 0.0139\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.01390\n",
      "Epoch 82/100\n",
      "11353/11353 [==============================] - 1s 79us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0139 - val_CRPS: 0.0139\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.01390\n",
      "Epoch 83/100\n",
      "11353/11353 [==============================] - 1s 79us/step - loss: 0.0141 - CRPS: 0.0141 - val_loss: 0.0140 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.01390\n",
      "Epoch 84/100\n",
      "11353/11353 [==============================] - 1s 78us/step - loss: 0.0141 - CRPS: 0.0140 - val_loss: 0.0140 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.01390\n",
      "Epoch 85/100\n",
      "11353/11353 [==============================] - 1s 76us/step - loss: 0.0140 - CRPS: 0.0141 - val_loss: 0.0140 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00085: saving model to ./mlp/weights/mlpWeights85.h5\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.01390\n",
      "Epoch 86/100\n",
      "11353/11353 [==============================] - 1s 77us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0140 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.01390\n",
      "Epoch 87/100\n",
      "11353/11353 [==============================] - 1s 75us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0139 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.01390\n",
      "Epoch 88/100\n",
      "11353/11353 [==============================] - 1s 77us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0139 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.01390\n",
      "Epoch 89/100\n",
      "11353/11353 [==============================] - 1s 77us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0140 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.01390\n",
      "Epoch 90/100\n",
      "11353/11353 [==============================] - 1s 75us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0140 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00090: saving model to ./mlp/weights/mlpWeights90.h5\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.01390\n",
      "Epoch 91/100\n",
      "11353/11353 [==============================] - 1s 76us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0140 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.01390\n",
      "Epoch 92/100\n",
      "11353/11353 [==============================] - 1s 76us/step - loss: 0.0140 - CRPS: 0.0141 - val_loss: 0.0140 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.01390\n",
      "Epoch 93/100\n",
      "11353/11353 [==============================] - 1s 77us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0139 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.01390\n",
      "Epoch 94/100\n",
      "11353/11353 [==============================] - 1s 76us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0139 - val_CRPS: 0.0139\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.01390\n",
      "Epoch 95/100\n",
      "11353/11353 [==============================] - 1s 78us/step - loss: 0.0140 - CRPS: 0.0141 - val_loss: 0.0139 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00095: saving model to ./mlp/weights/mlpWeights95.h5\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.01390\n",
      "Epoch 96/100\n",
      "11353/11353 [==============================] - 1s 76us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0140 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.01390\n",
      "Epoch 97/100\n",
      "11353/11353 [==============================] - 1s 75us/step - loss: 0.0140 - CRPS: 0.0141 - val_loss: 0.0139 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.01390\n",
      "Epoch 98/100\n",
      "11353/11353 [==============================] - 1s 77us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0140 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.01390\n",
      "Epoch 99/100\n",
      "11353/11353 [==============================] - 1s 75us/step - loss: 0.0140 - CRPS: 0.0140 - val_loss: 0.0139 - val_CRPS: 0.0139\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.01390\n",
      "Epoch 100/100\n",
      "11353/11353 [==============================] - 1s 75us/step - loss: 0.0141 - CRPS: 0.0141 - val_loss: 0.0139 - val_CRPS: 0.0140\n",
      "\n",
      "Epoch 00100: saving model to ./mlp/weights/mlpWeights100.h5\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.01390\n"
     ]
    }
   ],
   "source": [
    "# model training\n",
    "es = EarlyStopping(monitor='val_loss', \n",
    "                   mode='min',\n",
    "                   restore_best_weights=True, \n",
    "                   verbose=1, \n",
    "                   patience=21)\n",
    "es.set_model(model)\n",
    "\n",
    "lr = ReduceLROnPlateau(monitor='val_loss', \n",
    "                       factor=0.5,\n",
    "                       patience=10,\n",
    "                       verbose=1,\n",
    "                       mode='min',\n",
    "                       min_delta=0.00001)\n",
    "\n",
    "every5 = keras.callbacks.ModelCheckpoint(filepath='./mlp/weights/mlpWeights{epoch:02d}.h5', \n",
    "                                         verbose=1, save_best_only=False, period = 5)\n",
    "saveBest = keras.callbacks.ModelCheckpoint(filepath='./mlp/weights/mlpBestWeights.h5', \n",
    "                                           verbose=1, save_best_only=True)\n",
    "\n",
    "batch_size = 50\n",
    "epochs = 100\n",
    "\n",
    "history = model.fit(x=X_train, y=y_train,\n",
    "            validation_data = (X_val, y_val),\n",
    "            epochs = epochs,\n",
    "            batch_size = batch_size,\n",
    "            callbacks = [lr, every5, saveBest],\n",
    "            verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6952/6952 [==============================] - 0s 38us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test)\n",
    "np.save('./mlp/mlp_test_score.npy', score)\n",
    "np.save('./mlp/mlp_hist.npy', history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/mlp_data.npy',data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pids.index(20170910000081)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20328"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pids.index(20181206001238)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
